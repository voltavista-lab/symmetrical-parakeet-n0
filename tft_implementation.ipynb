{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Fusion Transformer for Electricity Price Forecasting\n",
    "\n",
    "This notebook implements TFT using PyTorch Forecasting for weekly electricity price prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install pytorch-forecasting pytorch-lightning torch pandas numpy matplotlib scikit-learn openpyxl xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import QuantileLoss, RMSE\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch Lightning version: {pl.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tft_data(csv_path, sheet_name, date_column='ini_date'):\n",
    "    \"\"\"\n",
    "    Prepare data for Temporal Fusion Transformer.\n",
    "    \n",
    "    Args:\n",
    "        csv_path: Path to the Excel file\n",
    "        sheet_name: Name of the sheet to read\n",
    "        date_column: Name of the date column\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame ready for TFT training\n",
    "    \"\"\"\n",
    "    # Read data\n",
    "    df = pd.read_excel(csv_path, sheet_name=sheet_name)\n",
    "    \n",
    "    # Convert date to datetime\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "    \n",
    "    # Sort by date\n",
    "    df = df.sort_values(date_column).reset_index(drop=True)\n",
    "    \n",
    "    # Create time index (sequential integer for each time step)\n",
    "    df['time_idx'] = range(len(df))\n",
    "    \n",
    "    # Create group identifier (needed for TFT, use submarket if available, else constant)\n",
    "    if 'submarket' in df.columns:\n",
    "        df['group'] = df['submarket']\n",
    "    else:\n",
    "        df['group'] = sheet_name\n",
    "    \n",
    "    # Add temporal features\n",
    "    df['month'] = df[date_column].dt.month\n",
    "    df['quarter'] = df[date_column].dt.quarter\n",
    "    df['year'] = df[date_column].dt.year\n",
    "    df['week_of_year'] = df[date_column].dt.isocalendar().week\n",
    "    \n",
    "    # Handle missing values\n",
    "    df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CSV_PATH = 'FINAL_INPUTS_v2.xls'\n",
    "SHEET_NAME = 'southeast'  # Change to 'northeast', 'north', 'south' as needed\n",
    "MAX_PREDICTION_LENGTH = 1  # Forecast horizon (1 week ahead)\n",
    "MAX_ENCODER_LENGTH = 52    # Look back window (52 weeks = 1 year)\n",
    "TRAINING_CUTOFF = None     # Will be set based on 70% split\n",
    "BATCH_SIZE = 64\n",
    "MAX_EPOCHS = 100\n",
    "\n",
    "# Load and prepare data\n",
    "df = prepare_tft_data(CSV_PATH, SHEET_NAME)\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Date range: {df['ini_date'].min()} to {df['ini_date'].max()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training cutoff (70% for training, 30% for validation)\n",
    "TRAINING_CUTOFF = int(len(df) * 0.7)\n",
    "print(f\"Training samples: {TRAINING_CUTOFF}\")\n",
    "print(f\"Validation samples: {len(df) - TRAINING_CUTOFF}\")\n",
    "print(f\"Training cutoff time_idx: {df.iloc[TRAINING_CUTOFF]['time_idx']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create TimeSeriesDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features\n",
    "# Target variable\n",
    "target = 'pld'\n",
    "\n",
    "# Time-varying known features (known in the future)\n",
    "# These are typically calendar features or planned interventions\n",
    "time_varying_known_reals = []  # Add if you have future-known continuous variables\n",
    "time_varying_known_categoricals = ['month', 'quarter', 'week_of_year']\n",
    "\n",
    "# Time-varying unknown features (only known up to present)\n",
    "# These are the features we want to use for prediction but don't know their future values\n",
    "time_varying_unknown_reals = [\n",
    "    'load_energy',\n",
    "    'max_demand',\n",
    "    'ena',\n",
    "    'hidro_gen',\n",
    "    'thermo_gen',\n",
    "    'stored_energy',\n",
    "    'exports',\n",
    "    'imports'\n",
    "]\n",
    "\n",
    "# Static features (constant for each group)\n",
    "static_categoricals = ['group']\n",
    "static_reals = []  # Add if you have static continuous features\n",
    "\n",
    "# Create training dataset\n",
    "training = TimeSeriesDataSet(\n",
    "    df[lambda x: x.time_idx <= TRAINING_CUTOFF],\n",
    "    time_idx='time_idx',\n",
    "    target=target,\n",
    "    group_ids=['group'],\n",
    "    min_encoder_length=MAX_ENCODER_LENGTH // 2,  # Allow some flexibility\n",
    "    max_encoder_length=MAX_ENCODER_LENGTH,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=MAX_PREDICTION_LENGTH,\n",
    "    static_categoricals=static_categoricals,\n",
    "    static_reals=static_reals,\n",
    "    time_varying_known_categoricals=time_varying_known_categoricals,\n",
    "    time_varying_known_reals=time_varying_known_reals,\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=time_varying_unknown_reals + [target],  # Add target to features\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=['group'], transformation='softplus'\n",
    "    ),  # Use softplus for positive values\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=False\n",
    ")\n",
    "\n",
    "# Create validation dataset\n",
    "validation = TimeSeriesDataSet.from_dataset(training, df, predict=True, stop_randomization=True)\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=BATCH_SIZE, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=BATCH_SIZE * 10, num_workers=0)\n",
    "\n",
    "print(f\"Training dataset size: {len(training)}\")\n",
    "print(f\"Validation dataset size: {len(validation)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure and Train TFT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure callbacks\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=1e-4,\n",
    "    patience=10,\n",
    "    verbose=False,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "lr_logger = LearningRateMonitor()\n",
    "\n",
    "# Configure logger\n",
    "logger = TensorBoardLogger(\"lightning_logs\")\n",
    "\n",
    "# Create trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    accelerator=\"auto\",  # Automatically uses GPU if available\n",
    "    devices=\"auto\",\n",
    "    gradient_clip_val=0.1,\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    "    enable_model_summary=True,\n",
    ")\n",
    "\n",
    "print(\"Trainer configured successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the TFT model\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=64,  # Size of hidden layers\n",
    "    attention_head_size=4,  # Number of attention heads\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=32,  # Size of hidden continuous variable processing\n",
    "    loss=QuantileLoss(),  # Use quantile loss for probabilistic forecasting\n",
    "    log_interval=10,  # Log every 10 batches\n",
    "    reduce_on_plateau_patience=4,  # Reduce learning rate if no improvement\n",
    "    optimizer=\"ranger\",  # Use Ranger optimizer (combination of RAdam and LookAhead)\n",
    ")\n",
    "\n",
    "print(f\"Model size: {tft.size()/1e3:.1f}k parameters\")\n",
    "print(\"\\nModel architecture:\")\n",
    "print(tft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Best Model and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model from checkpoint\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "print(f\"Loading best model from: {best_model_path}\")\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n",
    "\n",
    "# Make predictions on validation set\n",
    "print(\"\\nGenerating predictions on validation set...\")\n",
    "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "predictions = best_tft.predict(val_dataloader, mode=\"prediction\", return_x=False)\n",
    "\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "print(f\"Actuals shape: {actuals.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "actuals_np = actuals.cpu().numpy().flatten()\n",
    "predictions_np = predictions.cpu().numpy().flatten()\n",
    "\n",
    "# Remove any NaN values for metric calculation\n",
    "mask = ~(np.isnan(actuals_np) | np.isnan(predictions_np))\n",
    "actuals_clean = actuals_np[mask]\n",
    "predictions_clean = predictions_np[mask]\n",
    "\n",
    "rmse = sqrt(mean_squared_error(actuals_clean, predictions_clean))\n",
    "mae = np.mean(np.abs(actuals_clean - predictions_clean))\n",
    "mape = np.mean(np.abs((actuals_clean - predictions_clean) / actuals_clean)) * 100\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"PERFORMANCE METRICS ({SHEET_NAME.upper()})\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs actuals\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(actuals_clean, label='Actual', alpha=0.7, linewidth=2)\n",
    "plt.plot(predictions_clean, label='TFT Prediction', alpha=0.7, linewidth=2)\n",
    "plt.title(f'TFT Predictions vs Actuals - {SHEET_NAME.upper()}', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Time Steps', fontsize=12)\n",
    "plt.ylabel('Price (PLD)', fontsize=12)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'tft_predictions_{SHEET_NAME}.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Plot saved as: tft_predictions_{SHEET_NAME}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "residuals = actuals_clean - predictions_clean\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Residuals over time\n",
    "axes[0].plot(residuals, alpha=0.7)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "axes[0].set_title('Residuals Over Time', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Time Steps')\n",
    "axes[0].set_ylabel('Residual')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals distribution\n",
    "axes[1].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0, color='r', linestyle='--', alpha=0.5)\n",
    "axes[1].set_title('Residuals Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Residual')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'tft_residuals_{SHEET_NAME}.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Residuals plot saved as: tft_residuals_{SHEET_NAME}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Predictions vs Actuals\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(actuals_clean, predictions_clean, alpha=0.5, s=20)\n",
    "plt.plot([actuals_clean.min(), actuals_clean.max()], \n",
    "         [actuals_clean.min(), actuals_clean.max()], \n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual Price', fontsize=12)\n",
    "plt.ylabel('Predicted Price', fontsize=12)\n",
    "plt.title(f'TFT: Predicted vs Actual - {SHEET_NAME.upper()}', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'tft_scatter_{SHEET_NAME}.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Scatter plot saved as: tft_scatter_{SHEET_NAME}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance and Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get interpretation/feature importance\n",
    "print(\"Calculating feature importance...\")\n",
    "interpretation = best_tft.interpret_output(val_dataloader.dataset[:100], reduction=\"sum\")\n",
    "\n",
    "# Plot variable importance\n",
    "print(\"\\nVariable Importance:\")\n",
    "best_tft.plot_interpretation(interpretation)\n",
    "plt.savefig(f'tft_interpretation_{SHEET_NAME}.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Interpretation plot saved as: tft_interpretation_{SHEET_NAME}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare with LSTM Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LSTM benchmark results if available\n",
    "try:\n",
    "    benchmark_df = pd.read_excel('benchmark_consolidated.xlsx', sheet_name=SHEET_NAME)\n",
    "    \n",
    "    # Calculate LSTM metrics for comparison\n",
    "    lstm_rmse = sqrt(mean_squared_error(benchmark_df['actuals'], benchmark_df['predictions']))\n",
    "    decomp_rmse = sqrt(mean_squared_error(benchmark_df['actuals'], benchmark_df['decomp_predictions_as_of']))\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"MODEL COMPARISON ({SHEET_NAME.upper()})\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"TFT RMSE:          {rmse:.3f}\")\n",
    "    print(f\"LSTM RMSE:         {lstm_rmse:.3f}\")\n",
    "    print(f\"DECOMP RMSE:       {decomp_rmse:.3f}\")\n",
    "    print(f\"\\nTFT Improvement over LSTM:  {((lstm_rmse - rmse) / lstm_rmse * 100):.2f}%\")\n",
    "    print(f\"TFT Improvement over DECOMP: {((decomp_rmse - rmse) / decomp_rmse * 100):.2f}%\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not load benchmark data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to CSV\n",
    "results_df = pd.DataFrame({\n",
    "    'actual': actuals_clean,\n",
    "    'tft_prediction': predictions_clean,\n",
    "    'residual': residuals\n",
    "})\n",
    "\n",
    "results_df.to_csv(f'tft_results_{SHEET_NAME}.csv', index=False)\n",
    "print(f\"Results saved to: tft_results_{SHEET_NAME}.csv\")\n",
    "\n",
    "# Save model\n",
    "torch.save(best_tft.state_dict(), f'tft_model_{SHEET_NAME}.pt')\n",
    "print(f\"Model saved to: tft_model_{SHEET_NAME}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Make Future Predictions (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get raw predictions with quantiles for uncertainty estimation\n",
    "raw_predictions = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)\n",
    "\n",
    "# Plot predictions with uncertainty\n",
    "for idx in range(min(5, len(raw_predictions.x))):\n",
    "    best_tft.plot_prediction(raw_predictions.x, raw_predictions.output, idx=idx, add_loss_to_title=True)\n",
    "    plt.savefig(f'tft_uncertainty_{SHEET_NAME}_sample_{idx}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(f\"Uncertainty plots saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Data preparation for TFT with proper feature engineering\n",
    "2. TimeSeriesDataSet creation with appropriate normalizers\n",
    "3. TFT model configuration and training\n",
    "4. Comprehensive evaluation metrics (RMSE, MAE, MAPE)\n",
    "5. Multiple visualization types (predictions, residuals, scatter plots)\n",
    "6. Feature importance interpretation\n",
    "7. Comparison with LSTM baseline\n",
    "8. Uncertainty quantification with prediction intervals\n",
    "\n",
    "To use this for different submarkets, simply change the `SHEET_NAME` variable to 'northeast', 'north', or 'south'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
